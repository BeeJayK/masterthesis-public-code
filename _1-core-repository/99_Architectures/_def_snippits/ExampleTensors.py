#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Nov 16 14:06:20 2021

@author: marlinberger

Testscript to test tf functions and basic concepts to implement in custom
layers and stuff
"""
# python packages
import numpy as np
from tensorflow import keras
import tensorflow as tf


class E_Tensor():
    """provide different tensors to test layers with. putted them here, to
    have them in a central place, but also seperated from other scripts, as they
    are quiet spacious
    """

    def __init__(self):
        # fully filled, correct positions
        self.X1 = self.X_1()
        # no hands detected
        self.X2 = self.X_2()
        # one hand detected, on pos_0 but is right hand
        self.X3 = self.X_3()

    def simulate_ds_take(self, X, stacked_n, batch_size):
        """just stack repeat the tensor to have an instance that looks just
        as it would, if sampled from the dataset

        Args:
            X (tensor): tensor representation of one frame
            stacked_n (int): the sequence len
            batch_size (int): the batch size

        Returns:
            X (tensor): the input tensor, repeated and stacked to the same shape
                        than it has from the dataset
        """
        X = tf.stack([X for _ in range(stacked_n)], axis=0)
        X = tf.stack([X for _ in range(batch_size)], axis=0)
        return (X)

    def X_1(self):
        X = tf.convert_to_tensor(np.array([
            0.0,
            0.0,
            np.nan,
            0.0,
            0.94347614,
            0.5278015,
            0.7419184,
            0.0,
            0.42521375,
            0.70112526,
            -0.006801872,
            0.38450912,
            0.646151,
            -0.008340621,
            0.36659566,
            0.59568435,
            -0.006521786,
            0.3399493,
            0.5578878,
            -0.0024098735,
            0.5096504,
            0.5906203,
            -0.008902423,
            0.52432895,
            0.51949584,
            -0.0022879653,
            0.532338,
            0.4846093,
            0.013755593,
            0.5375453,
            0.46124297,
            0.02646553,
            0.5822598,
            0.59927833,
            -0.007434302,
            0.6082202,
            0.52547807,
            0.010703689,
            0.6219362,
            0.48733258,
            0.031397182,
            0.633807,
            0.46317142,
            0.043400113,
            0.6340009,
            0.61782074,
            -0.006598758,
            0.67239106,
            0.5580249,
            0.0029027013,
            0.69483393,
            0.5202059,
            0.007483405,
            0.7119966,
            0.49360418,
            0.009169904,
            0.67431146,
            0.6441479,
            -0.0073798145,
            0.72447544,
            0.6052981,
            -0.00790397,
            0.7527992,
            0.57823527,
            -0.010094917,
            0.7715067,
            0.55651915,
            -0.009758275,
            1.0,
            0.9863408,
            0.14552613,
            0.36447433,
            0.0,
            0.2444036,
            0.40273488,
            -0.02459638,
            0.33833164,
            0.39985934,
            -0.037453793,
            0.41929972,
            0.38508078,
            -0.03982964,
            0.48995644,
            0.38060135,
            -0.04228689,
            0.35733908,
            0.323777,
            -0.06716644,
            0.45844567,
            0.29203972,
            -0.074843735,
            0.5166433,
            0.27147096,
            -0.061633226,
            0.5548169,
            0.25909758,
            -0.046447195,
            0.3208596,
            0.29182684,
            -0.047331937,
            0.41493523,
            0.24176128,
            -0.038732085,
            0.44946307,
            0.23214996,
            -0.0004800558,
            0.46263158,
            0.23335013,
            0.029749526,
            0.2735939,
            0.2714617,
            -0.027122872,
            0.3645472,
            0.22521314,
            -0.02174415,
            0.40697944,
            0.21597612,
            0.008293773,
            0.43041173,
            0.21770501,
            0.031423848,
            0.22755137,
            0.26161838,
            -0.008893515,
            0.28198802,
            0.22155641,
            -0.011892008,
            0.32573783,
            0.20165455,
            -0.0013177563,
            0.36109975,
            0.19017214,
            0.01196103
        ], dtype=np.float32))
        return (X)

    def X_2(self):
        X = tf.convert_to_tensor(np.array([
            0.0,
            0.0,
            1.0,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan
        ], dtype=np.float32))
        return (X)

    def X_3(self):
        X = tf.convert_to_tensor(np.array([
            0.0,
            0.0,
            np.nan,
            1.0,
            0.5191278457641602,
            0.17580963671207428,
            0.3476232886314392,
            0.0,
            0.130859375,
            0.2916161119937897,
            0.003491042647510767,
            0.1294534057378769,
            0.2491263598203659,
            0.01074186246842146,
            0.13523365557193756,
            0.2163173258304596,
            0.010646126233041286,
            0.12156988680362701,
            0.18654298782348633,
            0.012644394300878048,
            0.25189611315727234,
            0.25538820028305054,
            0.06921179592609406,
            0.3045473098754883,
            0.22080934047698975,
            0.08060828596353531,
            0.34083086252212524,
            0.20090025663375854,
            0.08172953128814697,
            0.368825227022171,
            0.18461096286773682,
            0.0805845856666565,
            0.2943316102027893,
            0.2760713994503021,
            0.05753900855779648,
            0.36057335138320923,
            0.25823071599006653,
            0.06408297270536423,
            0.3507862091064453,
            0.2649981379508972,
            0.061861369758844376,
            0.3303139805793762,
            0.2724515497684479,
            0.0660884901881218,
            0.32569268345832825,
            0.2987362742424011,
            0.04088899493217468,
            0.38425561785697937,
            0.27761590480804443,
            0.04595116525888443,
            0.37298473715782166,
            0.2822873294353485,
            0.05139962211251259,
            0.35146209597587585,
            0.2904343903064728,
            0.058201488107442856,
            0.34999021887779236,
            0.3245939612388611,
            0.020715979859232903,
            0.4135114550590515,
            0.3046777844429016,
            0.021801315248012543,
            0.45257681608200073,
            0.28660014271736145,
            0.021732216700911522,
            0.47991812229156494,
            0.27188214659690857,
            0.025617584586143494,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
            np.nan,
        ], dtype=np.float32))
        return (X)
